# -*- coding: utf-8 -*-
"""trainer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qXXTYDRG_LV1tCM2IiX2B1dQOmsftMRn
"""

import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard
from tensorflow.keras.optimizers import Adam
from dataclasses import dataclass
from runner import *
from initial_parser import *
from splitter import *
from data_provider import *
from custom_models import *
from custom_metrics import *
from custom_losses import *
from iterstrat.ml_stratifiers import MultilabelStratifiedKFold
from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit
import os
import random
from tensorflow.keras.layers.experimental import preprocessing 
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import albumentations as A
import numpy as np
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
from keras.layers import BatchNormalization
from keras.layers.core import SpatialDropout2D, Activation
from tensorflow.keras.applications import EfficientNetB0
from keras import backend as K
from keras.layers.merge import concatenate
from keras.utils.data_utils import get_file
from tensorflow import keras
import segmentation_models as sm
import cv2
import datetime
from segmentation_models.losses import bce_jaccard_loss

class trainer_imseg():
  def __init__(self, input_model, input_optimizer, input_loss, input_metrics,
               input_batch_size, input_epochs, input_callbacks, input_log_name,
               input_net_info_path, input_model_checkpoints_path):
      self.current_model = input_model
      self.batch_size = input_batch_size
      self.optimizer = input_optimizer
      self.loss = input_loss
      self.metrics = input_metrics
      self.epochs = input_epochs
      self.custom_callbacks = input_callbacks
      self.log_name = input_log_name
      self.net_info_path =  input_net_info_path
      self.model_checkpoints_path = input_model_checkpoints_path
      
  def steps_per_epoch_calc(self, train_len, val_len):
    return [train_len // self.batch_size, val_len // self.batch_size]

  
  class lr_to_csvlogger(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs):
      logs['learning_rate'] = self.model.optimizer._decayed_lr('float32').numpy()
    

  def train(self, train_data, val_data, train_len, val_len, fold_num):
    epoch_steps, val_steps = self.steps_per_epoch_calc(train_len, val_len)
    self.current_model.compile(optimizer=self.optimizer, loss=self.loss, metrics = self.metrics)
    history = self.current_model.fit(train_data,
    validation_data=val_data,
    epochs=self.epochs,
    steps_per_epoch=epoch_steps,
    validation_steps=val_steps,
    callbacks=[self.lr_to_csvlogger(), CSVLogger(Path(self.net_info_path, f"model_{self.log_name}_fold_{fold_num}.csv")), 
          ModelCheckpoint(monitor='val_loss', filepath=Path(self.model_checkpoints_path, f"model_{self.log_name}_fold_{fold_num}.hdf5"), save_best_only=True),
          ] + self.custom_callbacks)
    return